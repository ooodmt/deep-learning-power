{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMAZON2014.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1u82aPl7N-joeWcOB1Mg-pfGcGHOk0MaH",
      "authorship_tag": "ABX9TyOTPnXj/UiVfj2p5dhG1kZB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uqPwlbMud12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "823cca15-15de-4bab-e490-893912ef1b4a"
      },
      "source": [
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkXYVio6Fg5Y",
        "colab_type": "text"
      },
      "source": [
        "## In this notebook I train simple bidirectional LSTM network to perform sentiment analysis on Amazon reviews dataset using TensorFlow. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrKMEl2sLLTc",
        "colab_type": "text"
      },
      "source": [
        "### Load positive and negative reviews from files and concatenate them into a single string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvGLNvpz1-id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pfad = '/content/drive/My Drive/colab/datasets/amazon2014'\n",
        "forbid = 'unlabeled'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbP6oQeJ2cPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "08c1c2e4-2882-4714-dae2-0e5461d38067"
      },
      "source": [
        "text = ''\n",
        "for i in os.listdir(pfad):\n",
        "  tmpdir = os.path.join(pfad,i)\n",
        "  print(i)\n",
        "  #if i == 'books':\n",
        "  for j in os.listdir(tmpdir):\n",
        "    print(j)\n",
        "    if forbid not in j:\n",
        "      tmpfile = os.path.join(tmpdir,j)\n",
        "      print(tmpfile)\n",
        "      with open(tmpfile) as file:\n",
        "        body = file.read()\n",
        "      print(len(body))\n",
        "      text = text + body"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dvd\n",
            "negative.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/dvd/negative.review\n",
            "1588827\n",
            "positive.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/dvd/positive.review\n",
            "1695767\n",
            "unlabeled.review\n",
            "books\n",
            "negative.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/books/negative.review\n",
            "1538070\n",
            "positive.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/books/positive.review\n",
            "1510847\n",
            "kitchen_&_housewares\n",
            "negative.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/kitchen_&_housewares/negative.review\n",
            "1019913\n",
            "unlabeled.review\n",
            "positive.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/kitchen_&_housewares/positive.review\n",
            "1018947\n",
            "electronics\n",
            "positive.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/electronics/positive.review\n",
            "1104976\n",
            "negative.review\n",
            "/content/drive/My Drive/colab/datasets/amazon2014/electronics/negative.review\n",
            "1113470\n",
            "unlabeled.review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3upKqyzX5pLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f464ba2-8e4a-46b1-98e5-5549fd520584"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10590817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bswZqEE85m6e",
        "colab_type": "text"
      },
      "source": [
        "Sample unprocessed data piece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ATId9eh5D8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b47318a5-9229-4f07-f577-83513bec3c01"
      },
      "source": [
        "text[:1600]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<review>\\n<unique_id>\\nB00064LJVE:one_of_the_worst_movies_i_have_ever_seen.:fer360\\n</unique_id>\\n<asin>\\nB00064LJVE\\n</asin>\\n<product_name>\\nThe Village (Widescreen Edition) (Vista Series): DVD: Jayne Atkinson,Adrien Brody,Frank Collison,Jesse Eisenberg,Brendan Gleeson,Judy Greer,Charlie Hofheimer,Bryce Dallas Howard,William Hurt,Cherry Jones,John Christopher Jones,Fran Kranz,Joaquin Phoenix,Michael Pitt (II),Pascale Renate Smith,Scott Sowers,Zack Wall,Sigourney Weaver,Celia Weston\\n</product_name>\\n<product_type>\\ndvd\\n</product_type>\\n<helpful>\\n0 of 4\\n</helpful>\\n<rating>\\n1.0\\n</rating>\\n<title>\\nOne of the worst movies I have ever seen.\\n</title>\\n<date>\\nOctober 29, 2006\\n</date>\\n<reviewer>\\nFer360\\n</reviewer>\\n<reviewer_location>\\nNew England, USA\\n</reviewer_location>\\n<review_text>\\nThis entire movie could have run in only 20 minutes and you wouldn\\'t miss anything and might even enjoy it. Unfortunately it ran 88 minutes too long and I couldn\\'t wait for it to end.  I saw it in the theater and the people all around me were all complaining how boring it was. At least a quarter of them walked out before the end. It\\'s that bad. It\\'s a shame, I love a good suspense/horror movie and the decent actors in this movies were waisted\\n</review_text>\\n</review>\\n<review>\\n<unique_id>\\nB0000TG9E2:another_classic,_ruined_by_disney:poopear_\"i_eat_$h!7\"\\n</unique_id>\\n<asin>\\nB0000TG9E2\\n</asin>\\n<product_name>\\nAlice in Wonderland (Masterpiece Edition): DVD: Kathryn Beaumont,Ed Wynn,Richard Haydn,Sterling Holloway,Jerry Colonna,Verna Felton,J. Pat O\\'Malley,Bill Thompson,Heather Angel,Joseph Kearns,Larry Grey,Queenie Le'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-fx5OQRES7V",
        "colab_type": "text"
      },
      "source": [
        "# Get all tag names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIMNLmaS50Vy",
        "colab_type": "text"
      },
      "source": [
        "Reviews are separated by `<review>` tags. Other tags demarcate different parameters of the review entry. We want data in DataFrame format for convenient analysis. For that let's first split the unprocessed data into a list of unprocessed reviews and then extract values of all parameters which we can further use to create a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlU4YJRI0yUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "bd03fe71-c855-4802-daf8-e71a71bed4d5"
      },
      "source": [
        "b = re.findall('<([\\w]*)>',text, flags=re.DOTALL)\n",
        "tag_names_small = list(set(b) - {'review'})\n",
        "tag_names = list(set(b))\n",
        "tag_names"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['helpful',\n",
              " 'reviewer_location',\n",
              " 'review_text',\n",
              " 'product_name',\n",
              " 'review',\n",
              " 'product_type',\n",
              " 'unique_id',\n",
              " 'title',\n",
              " 'date',\n",
              " 'rating',\n",
              " 'reviewer',\n",
              " 'asin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgCm2ZXK3jxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "40b1a049-591b-49f8-9a23-115ec094e771"
      },
      "source": [
        "tags_start = list(map(lambda x : '<'+x+'>', tag_names_small))\n",
        "tags_end = list(map(lambda x : '</'+x+'>', tag_names_small))\n",
        "merged = list(zip(tags_start, tags_end))\n",
        "merged"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<helpful>', '</helpful>'),\n",
              " ('<reviewer_location>', '</reviewer_location>'),\n",
              " ('<review_text>', '</review_text>'),\n",
              " ('<product_name>', '</product_name>'),\n",
              " ('<product_type>', '</product_type>'),\n",
              " ('<unique_id>', '</unique_id>'),\n",
              " ('<title>', '</title>'),\n",
              " ('<date>', '</date>'),\n",
              " ('<rating>', '</rating>'),\n",
              " ('<reviewer>', '</reviewer>'),\n",
              " ('<asin>', '</asin>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Wi8K7syYvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unproccessed_entries = re.findall('<review>\\\\n(.*?)\\\\n</review>\\\\n', text, flags=re.DOTALL)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuCMbKIX7XCL",
        "colab_type": "text"
      },
      "source": [
        "Sample unprocessed review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0DqQA8pH9RF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1f47d7e6-0bc0-454f-d8cb-a1e632ed707e"
      },
      "source": [
        "unproccessed_entries[-1000]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<unique_id>\\nB00005UKBG:bad:j._brodeur_\"disgusted_consumer\"\\n</unique_id>\\n<asin>\\nB00005UKBG\\n</asin>\\n<product_name>\\nAtlantic 1316 CD Storage Case (110-Capacity, Wave): Electronics\\n</product_name>\\n<product_type>\\nelectronics\\n</product_type>\\n<helpful>\\n15 of 16\\n</helpful>\\n<rating>\\n2.0\\n</rating>\\n<title>\\nbad\\n</title>\\n<date>\\nMay 4, 2005\\n</date>\\n<reviewer>\\nJ. Brodeur \"disgusted consumer\"\\n</reviewer>\\n<reviewer_location>\\n\\n</reviewer_location>\\n<review_text>\\ncons\\ntips extremely easy on carpet and if you have a lot of cds stacked at the top\\n\\npoorly designed, it is a vertical cd rack that doesnt have individual slots for cds, so if you want a cd from the bottom of a stack you have basically pull the whole stack to get to it\\n\\nputting it together was a pain, the one i bought i had to break a piece of metal just to fit it in its guide holes.\\n\\nagain..poorly designed... doesnt even fit cds that well, there are gaps, and the cd casses are loose fitting\\n\\npros\\n..........\\ni guess it can hold a lot of cds....\\n</review_text>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHWg-DjE-c9",
        "colab_type": "text"
      },
      "source": [
        "# Create DataFrame from dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VYBBHh_FOus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# given the tags extract corresponding values from each entry\n",
        "def col_entries(tag1, tag2, t):\n",
        "    return re.findall(tag1+'\\\\n(.*?)\\\\n'+tag2, text, flags=re.DOTALL)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvHHOH1CFCmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "f6872beb-ad57-4722-f164-15a813ba0d8b"
      },
      "source": [
        "# create dictionary\n",
        "d = {k:col_entries(tag_start, tag_end, text) for k, (tag_start, tag_end)  in zip(tag_names_small,merged)}\n",
        "for i in tag_names_small:\n",
        "  print(i, ': ',d[i][1])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "helpful :  2 of 25\n",
            "reviewer_location :  Acidville, CA\n",
            "review_text :  If you are looking for a good movie to buy for your child, pass on this one. This movie has so many drug references, i can't even begin to explain.(trust me, I just so happen to have taken acid before) This is a movie that NEVER should have been directed toward children. \n",
            "  \n",
            "   If you want your child to be drug free when he/she grows up, do not buy this\n",
            "product_name :  Alice in Wonderland (Masterpiece Edition): DVD: Kathryn Beaumont,Ed Wynn,Richard Haydn,Sterling Holloway,Jerry Colonna,Verna Felton,J. Pat O'Malley,Bill Thompson,Heather Angel,Joseph Kearns,Larry Grey,Queenie Leonard,Dink Trout,Doris Lloyd,James MacDonald (II),Bill Lee (IV),Thurl Ravenscroft,Max Smith,Bob Hamlin,Don Barclay,Wilfred Jackson,Clyde Geronimi,Hamilton Luske\n",
            "product_type :  dvd\n",
            "unique_id :  B0000TG9E2:another_classic,_ruined_by_disney:poopear_\"i_eat_$h!7\"\n",
            "title :  Another classic, ruined by Disney\n",
            "date :  July 1, 2006\n",
            "rating :  1.0\n",
            "reviewer :  poopear \"i eat $h!7\"\n",
            "asin :  B0000TG9E2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7zUW0Nsy0Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgB96cdo7qpj",
        "colab_type": "text"
      },
      "source": [
        "Now let's process our data further by removing exceedingly long reviews (longer than 4000 characters) and dropping irrelevant columns. Let's also cast all words in all reviews to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKcf5KN2ztIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(index=df[df.review_text.str.len()>4000].index,\n",
        "             columns=['unique_id', 'date', 'reviewer', 'product_name', 'reviewer_location', 'helpful', 'asin'])\n",
        "df.rename(columns={'review_text':'text'}, inplace=True)\n",
        "df.rating = df.rating.astype(float)\n",
        "df.text = df.text.str.lower()\n",
        "df = df.sample(df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxdl9S7x30-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b9a559ee-5301-4b8a-d91c-89d238bfcdfd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>product_type</th>\n",
              "      <th>title</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>on the surface this film is a pretty good cour...</td>\n",
              "      <td>dvd</td>\n",
              "      <td>Subtexts</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>cup leaks out of the top closure part. i need ...</td>\n",
              "      <td>kitchen &amp; housewares</td>\n",
              "      <td>Cup leaks</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6931</th>\n",
              "      <td>this printer was purchased for my wife's birth...</td>\n",
              "      <td>electronics</td>\n",
              "      <td>HP  Photosmart 335 Printer</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2846</th>\n",
              "      <td>if you look at the march 2004 issue of the int...</td>\n",
              "      <td>books</td>\n",
              "      <td>Don't buy this book. Check with the experts in...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5470</th>\n",
              "      <td>this peeler is amazing, and really inexpensive...</td>\n",
              "      <td>kitchen &amp; housewares</td>\n",
              "      <td>Best Peeler Ever!</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... rating\n",
              "878   on the surface this film is a pretty good cour...  ...    2.0\n",
              "4805  cup leaks out of the top closure part. i need ...  ...    1.0\n",
              "6931  this printer was purchased for my wife's birth...  ...    5.0\n",
              "2846  if you look at the march 2004 issue of the int...  ...    1.0\n",
              "5470  this peeler is amazing, and really inexpensive...  ...    5.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qPJbnod42-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1f25cc7e-a8c3-434a-935c-d82b43d04d35"
      },
      "source": [
        "df.rating.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    2839\n",
              "1.0    2405\n",
              "2.0    1552\n",
              "4.0    1107\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWerqZYk8G4d",
        "colab_type": "text"
      },
      "source": [
        "Here a small simplification is made. The model will be trained to classify reviews as `positive` or `negative` since predicting exact number of stars is a sort of ill-posed problem: number of stars is very subjective and one often cannot exactly say whether a negative review is two or one star, same with positive. For this reason and due to the absence of 3-star reviews we'll assign all entries with 1 and 2 stars a `negative` label and all with 4 or 5 a `positive` label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttq2QNkwIpUg",
        "colab_type": "text"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkXnJtssVFOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_working = df.copy()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzFWJFrrLw_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_working['mood'] = (df_working.rating > 2).astype(int)\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHCuekVN1TR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "7321f5b4-6152-482b-942b-fada19043009"
      },
      "source": [
        "df_working.sample(1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>product_type</th>\n",
              "      <th>title</th>\n",
              "      <th>rating</th>\n",
              "      <th>mood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>saw this as an inflight movie. boy, did i pray...</td>\n",
              "      <td>dvd</td>\n",
              "      <td>Praying for engine trouble!</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ... mood\n",
              "111  saw this as an inflight movie. boy, did i pray...  ...    0\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHqCa5i-5reQ",
        "colab_type": "text"
      },
      "source": [
        "# Create vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI8ehIhb-ISz",
        "colab_type": "text"
      },
      "source": [
        "Here I want to use `word_tokenize()` from NLTK library as tokenizer in `TokenTextEncoder` since it's a better tokenizer than the standard one in TensorFlow. However `TokenTextEncoder` only accepts objects with `tokenize()` function, meaning I need to wrap `nltk.word_tokenize()` with a class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ8fRqqzClKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class-wrapper for tokenize() function.\n",
        "class CustomTokenizer():\n",
        "  \n",
        "  def tokenize(self, text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "ct = CustomTokenizer()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt7UYzzh-vQR",
        "colab_type": "text"
      },
      "source": [
        "Create vocabulary from all texts and use it to train `TokenTextEncoder`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIiBt0_OtXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = Counter()\n",
        "\n",
        "df_working.text.apply(lambda x: counter.update(nltk.word_tokenize(x)))\n",
        "\n",
        "encoder = tfds.features.text.TokenTextEncoder(list(counter.keys()), tokenizer=ct)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqyl0wCp51PK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = pd.DataFrame({'word':list(counter.keys()),'n':list(counter.values())})"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFXKWYjoAyM2",
        "colab_type": "text"
      },
      "source": [
        "Create a vocabulary of words with less than five occurences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBQUMjoHBPeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rare = set(words[words.n < 5].word.to_numpy())\n",
        "rare_enc = set([encoder.encode(rare_word)[0] for rare_word in rare])\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOu2cNyVBNrk",
        "colab_type": "text"
      },
      "source": [
        "Set to zeros encoding values of least frequent words in the internal dictionary of `TokenTextEncoder`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpNHwwOEMtGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for least_frequent in rare:\n",
        "  encoder._token_to_id[least_frequent] = 0 "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjOvlVFkGQGx",
        "colab_type": "text"
      },
      "source": [
        "Let's create a dataset from strings of text and then transform them into arrays of separately encoded words with `Dataset.map()` function. Since this is graph execution one might want to use `tf.py_function()` to wrap the function that does the actual transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBSikpsWG9C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(target,label):\n",
        "  return encoder.encode(target.numpy()),tf.cast(label,tf.int64)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jNljTowDKtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(target,label):\n",
        "  res = tf.py_function(g, inp = [target,label], Tout=(tf.int64,tf.int64))\n",
        "  return res"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQVJyb7oOzY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_orig = tf.data.Dataset.from_tensor_slices((df_working.text, df_working.mood))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzG0CsvHDOgz",
        "colab_type": "text"
      },
      "source": [
        "Apply the transformation, shuffle and pad the samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SllCDScGJ8mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset_orig.map(f).shuffle(df.shape[0]).padded_batch(batch_size=8, padded_shapes=([None], []))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfFdkqg8O096",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c91b1c06-758d-40bb-b891-4897165e8d81"
      },
      "source": [
        "for i in dataset.take(2):\n",
        "  print(i)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(8, 243), dtype=int64, numpy=\n",
            "array([[   2,  446,   77, ...,    0,    0,    0],\n",
            "       [ 135,    6, 1223, ...,  107,  289,   12],\n",
            "       [  71,   19,  114, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 616,  135,    6, ...,    0,    0,    0],\n",
            "       [  71,  486, 1974, ...,    0,    0,    0],\n",
            "       [ 202,   92,  794, ...,    0,    0,    0]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 0, 1, 0, 1, 0, 1, 1])>)\n",
            "(<tf.Tensor: shape=(8, 288), dtype=int64, numpy=\n",
            "array([[1704,   21,    9, ...,    0,    0,    0],\n",
            "       [ 616,    1,    1, ...,   12, 9469,    1],\n",
            "       [ 369,    7, 2380, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  71,  114,  445, ...,    0,    0,    0],\n",
            "       [8980, 1487,   14, ...,    0,    0,    0],\n",
            "       [ 428,  422,   34, ...,    0,    0,    0]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 1, 1, 0, 0, 0, 0, 0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZFia5HCOz6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cded4d9-60a7-4b4f-af26-50095787220b"
      },
      "source": [
        "N = dataset.cardinality().numpy()\n",
        "N"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csoV-UyBDC-k",
        "colab_type": "text"
      },
      "source": [
        "Split dataset into training, test and validation sets as 80 / 10 / 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4z4n7s7OtC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test = dataset.skip(N//5),dataset.take(N//5)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0tovdnyElu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid, test = test.take(N//10), test.skip(N//10)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nugy4SpAE5oM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "263c708a-6e96-4a6c-996d-4e60343c75d4"
      },
      "source": [
        "train.cardinality().numpy() + test.cardinality().numpy() + valid.cardinality().numpy()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpbxMmFdGs8z",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z27bucFVdi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chkppts_path = '/content/drive/My Drive/colab/chkpts'\n",
        "mc_callback = tf.keras.callbacks.ModelCheckpoint(chkppts_path, save_best_only=True)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c74fwTNIdyYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 64"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFQyn_oENBgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(len(counter.items())+1, dim))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(dim)))\n",
        "model.add(tf.keras.layers.Dense(dim))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FICFx3r_NwCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huvx1moaOI1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "712ff10e-5c21-42a6-9f61-576babc72093"
      },
      "source": [
        "model.fit(train, epochs=5, validation_data=valid, callbacks=mc_callback)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.6743WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 264s 334ms/step - loss: 0.5967 - accuracy: 0.6743 - val_loss: 0.3435 - val_accuracy: 0.8597\n",
            "Epoch 2/5\n",
            "791/791 [==============================] - 250s 316ms/step - loss: 0.4193 - accuracy: 0.8116 - val_loss: 0.3926 - val_accuracy: 0.8151\n",
            "Epoch 3/5\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.8860INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 263s 333ms/step - loss: 0.2952 - accuracy: 0.8860 - val_loss: 0.1952 - val_accuracy: 0.9196\n",
            "Epoch 4/5\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9328INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 260s 329ms/step - loss: 0.1869 - accuracy: 0.9328 - val_loss: 0.1641 - val_accuracy: 0.9554\n",
            "Epoch 5/5\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9445INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 263s 332ms/step - loss: 0.1611 - accuracy: 0.9445 - val_loss: 0.1009 - val_accuracy: 0.9719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76706732b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ7ZS-LFd15E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "46be8a02-2cda-4e3b-a68d-168500fa37ad"
      },
      "source": [
        "model.evaluate(test)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99/99 [==============================] - 4s 41ms/step - loss: 0.0908 - accuracy: 0.9735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0908358246088028, 0.9734848737716675]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVR0u9qSOH28",
        "colab_type": "text"
      },
      "source": [
        "The validation accuracy is already high. Let's try to train model for few more epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXw51mQbKtW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a02d7dbc-c1f2-42fb-af7a-7b29f150b883"
      },
      "source": [
        "model.fit(train, epochs=3, validation_data=valid, callbacks=mc_callback)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9646INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 265s 335ms/step - loss: 0.1012 - accuracy: 0.9646 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
            "Epoch 2/3\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9633INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 266s 336ms/step - loss: 0.1076 - accuracy: 0.9633 - val_loss: 0.0708 - val_accuracy: 0.9758\n",
            "Epoch 3/3\n",
            "791/791 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9633INFO:tensorflow:Assets written to: /content/drive/My Drive/colab/chkpts/assets\n",
            "791/791 [==============================] - 269s 340ms/step - loss: 0.1056 - accuracy: 0.9633 - val_loss: 0.0584 - val_accuracy: 0.9809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f765b5cd668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ihd1dz6OFVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "92f3190f-4c3f-4ddc-e1fa-cbcc86025a8c"
      },
      "source": [
        "model.evaluate(test)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99/99 [==============================] - 4s 39ms/step - loss: 0.0556 - accuracy: 0.9811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.055553827434778214, 0.9810606241226196]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HKSucLqcmZX",
        "colab_type": "text"
      },
      "source": [
        "An increase of roughly 0.01 after 3 epochs is a fairly small one. Apparently the model starts to overfit so I'd better stop here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UBZ-1ZiOVYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(chkppts_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}